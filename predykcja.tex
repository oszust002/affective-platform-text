\chapter{Mechanizm predykcji emocji}
\label{cha:predykcja}
Jednym z~zadań niniejszej pracy jest przygotowanie mechanizmu umożliwiającego odczyt emocji na podstawie danych zebranych przy pomocy urządzeń przedstawionych w~rozdziale~\ref{cha:architektura}. Zdecydowano się na przygotowanie modelu uczenia maszynowego, który na podstawie cech wyciągniętych z~sygnałów fizjologicznych będzie w~stanie określić stan emocjonalny użytkownika. Aby uniezależnić przygotowywany model od silnika, w~którym będzie przygotowywana gra, zdecydowano się przygotować go w~języku Python, przy pomocy biblioteki scikit-learn służącej do tworzenia modeli uczenia maszynowego. Komunikacja modelu z~grą będzie odbywała się poprzez zapytanie HTTP, które na wejściu powinno przyjmować dane fizjologiczne odczytane z~danego zakresu czasu, na wyjściu zwracając reprezentację emocji określoną w~modelu. 

W tym rozdziale zostanie opisany proces przygotowywania modelu do rozpoznawania emocji. Zostaną opisane wykorzystane zbiory danych treningowych, sposób ich wstępnego przetworzenia, wybór cech i~klas emocji, oraz proces uczenia i~wyboru najlepszego modelu. Dokładny sposób komunikacji serwera z~ grą zostanie opisany w~rozdziale~\ref{cha:implementacja}.
\section{Zbiory danych}
W trakcie poszukiwania zbiorów uczących nie znaleziono niestety takich, które jednocześnie wykorzystywałyby pomiary pracy serca oraz akcelerometru. Zdecydowano więc o~wyborze zbiorów, które zawierały pomiary pracy serca i~to na ich podstawie określony zostanie stan emocjonalny zwracany przez model. Odczyty z~akcelerometru zostaną wykorzystane jako dodatkowy kontekst korygujący określony stan emocjonalny, o~czym więcej jest wspomniane w~rozdziale~\ref{cha:implementacja}.

\subsection{DEAP}
DEAP\footnote{A Database for Emotion Analysis using Physiological Signals}~\cite{deap_dataset_2011} to zbiór danych zawierający pomiary przeprowadzone na 32~osobach w~wieku 19-37. Każdy z~badanych został poddany eksperymentowi, w~ramach którego musiał obejrzeć 40~fragmentów teledysków, każdy z~nich trwający 60~sekund. Każdy z~nich był dostosowany w~ten sposób, aby wywoływać konkretny rodzaj emocji. Uczestnicy oceniali każdy z~fragmentów w~czterech skalach: \textit{valence} określający poziom przyjemności odczuwanej podczas oglądania, \textit{arousal} opisujący pobudzenie użytkownika, \textit{dominance} wskazujący poziom kontroli nad odczuwanymi emocjami oraz \textit{liking} opisujący jak bardzo materiał wideo podobał się osobie badanej. W~trakcie badań uczestnicy byli podłączeni do specjalistycznych przyrządów pomiarowych, przy pomocy których zebrano następujące dane fizjologiczne: elektroencefalogram (EEG), ciśnienie krwi (BVP), reakcja elektrodermalną (GSR), elektromiogram (EMG), objętość oddechowa, temperatura skóry oraz elektrookulogram. Poza tym, dla 22~uczestników dostępne były również nagrania twarzy. 

Dane udostępnione zostały w~dwóch wersjach: oryginalnej oraz wstępnie przetworzonej. Wersja oryginalna zawierała pełne odczyty, próbkowane z~częstotliwością 512~Hz. W~wersji przetworzonej, próbkowanie zostało zmniejszone do 128~Hz i~usunięte zostały 3~pierwsze sekundy stanowiące czas na przygotowanie się uczestników do badania. Część odczytów została także przefiltrowana i~uśredniona względem pomiarów wszystkich uczestników.

\subsection{AMIGOS}
AMIGOS\footnote{A Dataset for Affect, Personality and Mood Research on Individuals and Groups}~\cite{amigos_dataset_2017} jest zbiorem zawierającym dane zebrane podczas dwóch rodzajów eksperymentów:
\begin{enumerate}
	\item 16~krótkich fragmentów filmów hollywoodzkich wybranych ze zbioru DECAF~\cite{decaf_dataset_2015} o~długości 51--150 s ocenianych przez grupę 40~osób.
	\item 4~długie materiały wideo o~długości 14.1--23.58 min ocenianych przez 37~osób.
\end{enumerate}
Podobnie jak w~przypadku zbioru DEAP, uczestnicy mieli ocenić fragmenty wideo w~kilku skalach: \textit{valence}, \textit{arousal}, \textit{dominance}, \textit{liking} oraz \textit{familiarity} określający poziom znajomości fragmentu wideo. Każdy z~badanych miał także zaznaczyć jaką emocję odczuwał podczas oglądania danego materiału, mając do wyboru: emocję neutralną, odrazę, radość, zaskoczenie, złość, strach i~smutek. W~trakcie badań zostały zebrane następujące dane pomiarowe: elektroencefalogram (EEG), elektrokardiogram (ECG), reakcja elektrodermalna (GSR), nagrania wideo twarzy osób badanych oraz nagrania całego ciała wykonane przy pomocy urządzenia Kinect V1. W~przypadku danych z~elektrokardiogramu pomiary zostały przeprowadzone na lewym i~prawym ramieniu.

Zbiór został udostępniony w~dwóch wersjach: oryginalnej, dla której w~zależności od odczytywanego sygnału dane są próbkowane z~częstotliwością 128~lub 256~Hz, oraz wstępnie przetworzonej. W~tej drugiej, próbkowanie wszystkich odczytów zostało zmniejszone do 128~Hz, dane zostały uśrednione względem wszystkich pomiarów, oraz wstępnie przefiltrowane przy pomocy filtrów dolnoprzepustowych.
\subsection{ASCERTAIN}
ASCERTAIN\footnote{a multimodal databa\textbf{AS}e for impli\textbf{C}it p\textbf{ER}sonali\textbf{T}y and \textbf{A}ffect recognit\textbf{I}o\textbf{N} using commercial physiological sensors}~\cite{ascertain_dataset_2016} to zbiór danych zebranych podczas badań, w~ramach których 56~osób obejrzało 36~materiałów wideo o~średniej długości 80~s. Każdy z~uczestników oceniał materiały wideo w~pięciu skalach: \textit{valence} w~zakresie od -3~do 3, \textit{arousal} od 0~do 6, \textit{liking}, \textit{familiarity} oraz \textit{engagement} opisujący poziom zaangażowania użytkownika w~oglądanie danego fragmentu wideo. Przed przystąpieniem do badania, uczestnicy musieli wypełnić kwestionariusze osobowości BFMS\footnote{big-five marker scale}.  W~trakcie badań zebrano następujące dane pomiarowe: elektrokardiogram (ECG), reakcja elektrodermalna (GSR), elektroencefalogram (EEG) oraz pomiar punktów orientacyjnych twarzy. Podobnie jak w~przypadku zbioru ASCERTAIN, pomiar elektrokardiogramu odbywał się na lewym i~prawym ramieniu. Częstotliwości próbkowań były zależne od odczytywanego sygnału: EEG -- 32~Hz, ECG -- 256~Hz, GSR -- 128~Hz.

W ramach zbioru danych udostępnione zostały także cechy wyliczone na podstawie zebranych pomiarów, które mogły zostać wykorzystane jako gotowe dane do uczenia modelu maszynowego. Elementem zawartym w~zbiorze, który wyróżnia go na tle innych opisanych, jest plik zawierający wyniki wstępnej analizy zebranych danych, które zostały określone w~skali od 1~oznaczającego dane perfekcyjne do 6~opisującego brak danych lub błędy w~pomiarach. Dzięki temu, w~zależności od wymaganej jakości odczytanych danych, można przeprowadzić wstępną filtrację pomiarów.

\subsection{DECAF}
DECAF\footnote{MEG-Based Multimodal Database for Decoding Affective Physiological Responses}~\cite{decaf_dataset_2015} jest zbiorem zawierających pomiary zebrane podczas eksperymentów przeprowadzonych na 16~mężczyznach i~14 kobietach o~średniej wieku 27~lat. Uczestnicy w~trakcie badań oglądali materiały z~dwóch zbiorów:
\begin{enumerate}
	\item  40~fragmentów teledysków wykorzystywanych w~opisywanym wcześniej zbiorze DEAP~\cite{deap_dataset_2011}.
	\item 36~fragmentów wyciętych z~hollywoodzkich filmów o~średnim czasie trwania 80~sekund.
\end{enumerate}
Podobnie jak w~przypadku pozostałych zbiorów, uczestnicy mieli ocenić każdy fragment przy pomocy następujących skal: \textit{valence} w~zakresie od -2~do 2, \textit{arousal} od 0~do 4~oraz \textit{dominance} o~zakresie takim jak w~przypadku \textit{arousal}. W~trakcie badań zebrano dane o~następujących sygnałach fizjologicznych: magnetoencefalogram (MEG), elektromiogram (EMG), elektrokardiogram (ECG). Zebrano także nagrania twarzy każdego z~uczestników w~bliskiej podczerwieni. Dane były gromadzone z~próbkowaniem o~częstotliwości 1000~Hz, co daje dużą ilość danych, jednak z~drugiej strony może wprowadzać wyraźne błędy w~pomiarach. Poza oryginalnymi odczytami, w~ramach zbioru zostały udostępnione wyliczone cechy dla każdego z~pomiarów, które mogą być wykorzystane jako gotowy, przetworzony zestaw danych wykorzystywanych do stworzenia modelu. Ze względu na generyczny sposób przetworzenia danych na wszystkich używanych zbiorach, zdecydowano się skorzystać jednak z~oryginalnych pomiarów. 

\section{Przetworzenie danych}
Opis preprocessingu, wykorzystane cechy
\section{Wybór modelu}
Ewaluacja w~hyperopt, statystyki skuteczności, ostateczny wybór modelu