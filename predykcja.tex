\chapter{Mechanizm predykcji emocji}
\label{cha:predykcja}
Jednym z~zadań niniejszej pracy jest opracowanie mechanizmu umożliwiającego odczyt emocji na podstawie danych zebranych przy pomocy urządzeń przedstawionych w~rozdziale~\ref{cha:architektura}. Zdecydowano się na przygotowanie modelu uczenia maszynowego, który na podstawie cech wyciągniętych z~sygnałów fizjologicznych będzie w~stanie określić stan emocjonalny użytkownika. Aby uniezależnić przygotowywany model od silnika, w~którym będzie stworzona gra, zdecydowano się przygotować go w~języku Python przy pomocy biblioteki scikit-learn służącej do tworzenia modeli uczenia maszynowego. Komunikacja modelu z~grą będzie odbywała się poprzez zapytanie HTTP przyjmujące na wejściu dane fizjologiczne odczytane z~danego zakresu czasu. Na wyjściu zwracana będzie reprezentacja emocji określona w~modelu. 

W tym rozdziale opisano proces przygotowywania modelu do rozpoznawania stanów emocjonalnych. Zostaną opisane wykorzystane zbiory danych treningowych, sposób ich wstępnego przetworzenia, wybór cech i~klas, oraz proces uczenia i~wyboru najlepszego modelu. Rozwiązanie dotyczące komunikacji serwera z~grą zostanie opisane w~rozdziale~\ref{cha:implementacja}.
\section{Zbiory danych}
W trakcie poszukiwania zbiorów uczących nie znaleziono niestety takich, które jednocześnie wykorzystywałyby pomiary pracy serca oraz akcelerometru. Zdecydowano więc o~wyborze danych zawierających odczyty pracy serca, i~to na ich podstawie określony zostanie stan emocjonalny zwracany przez model. Wartości z~akcelerometru zostaną wykorzystane jako dodatkowy kontekst korygujący klasę emocji zwracaną przez model, o~czym więcej jest wspomniane w~rozdziale~\ref{cha:implementacja}.

\subsection{DEAP}
DEAP\footnote{A Database for Emotion Analysis using Physiological Signals}~\cite{deap_dataset_2011} to zbiór danych zawierający pomiary przeprowadzone na 32~osobach w~wieku 19--37 lat. Każdy z~badanych został poddany eksperymentowi, w~ramach którego musiał obejrzeć 40~fragmentów teledysków, każdy z~nich trwający 60~sekund. Były one dostosowane w~taki sposób, aby wywoływać konkretny rodzaj emocji. Uczestnicy oceniali każdy z~fragmentów w~czterech skalach: \textit{valence} określający przyjemność odczuwaną podczas oglądania, \textit{arousal} opisujący pobudzenie użytkownika, \textit{dominance} wskazujący poziom kontroli nad odczuwanymi emocjami oraz \textit{liking} warunkujący jak bardzo materiał wideo podobał się osobie badanej. W~trakcie badań uczestnicy byli podłączeni do specjalistycznych przyrządów pomiarowych, przy pomocy których zebrano następujące dane fizjologiczne: elektroencefalogram (EEG), puls objętości krwi (BVP), reakcja elektrodermalną (GSR), elektromiogram (EMG), objętość oddechowa, temperatura skóry oraz elektrookulogram. Poza tym, dla 22~uczestników dostępne były również nagrania twarzy. 

Dane udostępnione zostały w~dwóch wersjach: oryginalnej oraz poddanej wstępnej obróbce. Wersja oryginalna zawierała pełne odczyty, próbkowane z~częstotliwością 512~Hz. W~wersji przetworzonej, próbkowanie zostało zmniejszone do 128~Hz i~usunięte zostały 3~pierwsze sekundy stanowiące czas na przygotowanie się uczestników do badania. Część danych została także przefiltrowana i~uśredniona względem pomiarów wszystkich osób badanych.

\subsection{AMIGOS}
AMIGOS\footnote{A Dataset for Affect, Personality and Mood Research on Individuals and Groups}~\cite{amigos_dataset_2017} jest zbiorem zawierającym dane zebrane podczas dwóch rodzajów eksperymentów:
\begin{enumerate}
	\item 16~krótkich fragmentów filmów hollywoodzkich wybranych ze zbioru DECAF~\cite{decaf_dataset_2015} o~długości 51--150 s ocenianych przez grupę 40~osób.
	\item 4~długie materiały wideo o~długości 14.1--23.58 min ocenianych przez 37~osób.
\end{enumerate}
Podobnie jak w~przypadku zbioru DEAP, uczestnicy mieli ocenić fragmenty wideo w~kilku skalach: \textit{valence}, \textit{arousal}, \textit{dominance}, \textit{liking} oraz \textit{familiarity} określający poziom znajomości fragmentu wideo. Każdy z~badanych miał także zaznaczyć jaką emocję odczuwał podczas oglądania danego materiału, mając do wyboru: emocję neutralną, odrazę, radość, zaskoczenie, złość, strach i~smutek. W~trakcie badań zostały zebrane następujące dane pomiarowe: elektroencefalogram (EEG), elektrokardiogram (ECG), reakcja elektrodermalna (GSR), nagrania wideo twarzy osób badanych oraz nagrania całego ciała wykonane przy pomocy urządzenia Kinect V1. W~przypadku danych z~elektrokardiogramu pomiary zostały przeprowadzone na lewym i~prawym ramieniu.

Zbiór został udostępniony w~dwóch wersjach: oryginalnej, dla której w~zależności od odczytywanego sygnału dane są próbkowane z~częstotliwością 128~lub 256~Hz, oraz wstępnie przetworzonej. W~tej drugiej, próbkowanie sygnałów zostało zmniejszone do 128~Hz, wartości zostały uśrednione względem wszystkich pomiarów, oraz wstępnie przefiltrowane przy pomocy filtrów dolnoprzepustowych.

\subsection{ASCERTAIN}
ASCERTAIN\footnote{a multimodal databa\textbf{AS}e for impli\textbf{C}it p\textbf{ER}sonali\textbf{T}y and \textbf{A}ffect recognit\textbf{I}o\textbf{N} using commercial physiological sensors}~\cite{ascertain_dataset_2016} to zbiór danych zebranych podczas badań, w~ramach których 56~osób obejrzało 36~materiałów wideo o~średniej długości 80~s. Każdy z~uczestników oceniał materiały wideo w~pięciu skalach: \textit{valence} w~zakresie od -3~do 3, \textit{arousal} od 0~do 6, \textit{liking}, \textit{familiarity} oraz \textit{engagement} opisujący poziom zaangażowania użytkownika w~oglądanie danego fragmentu wideo. Przed przystąpieniem do badania, uczestnicy musieli wypełnić kwestionariusze osobowości BFMS\footnote{big-five marker scale}.  W~trakcie badań zebrano następujące dane pomiarowe: elektrokardiogram (ECG), reakcja elektrodermalna (GSR), elektroencefalogram (EEG) oraz pomiar punktów orientacyjnych twarzy. Podobnie jak w~przypadku zbioru ASCERTAIN, odczyt z~elektrokardiogramu odbywał się na lewym i~prawym ramieniu. Częstotliwości próbkowań były zależne od typu sygnału: EEG --- 32~Hz, ECG --- 256~Hz, GSR --- 128~Hz.

W ramach zbioru udostępnione zostały także cechy wyliczone na podstawie zebranych pomiarów, które mogły zostać wykorzystane jako gotowe dane do uczenia modelu maszynowego. Elementem zawartym w~ASCERTAIN, który wyróżnia go na tle innych opisanych zbiorów, jest plik zawierający wyniki wstępnej analizy zebranych wartości, które zostały określone w~skali od 1~oznaczającego dane perfekcyjne do 6~opisującego brak danych lub błędy w~pomiarach.  Udostępniona została także lista eksperymentów zakończonych niepowodzeniem. Dzięki temu, w~zależności od wymaganej jakości odczytanych danych, można przeprowadzić ich wstępną filtrację.

\subsection{DECAF}
DECAF\footnote{MEG-Based Multimodal Database for Decoding Affective Physiological Responses}~\cite{decaf_dataset_2015} jest zbiorem zawierających pomiary zebrane podczas eksperymentów przeprowadzonych na 16~mężczyznach i~14 kobietach o~średniej wieku 27~lat. Uczestnicy w~trakcie badań oglądali materiały z~dwóch grup:
\begin{enumerate}
	\item  40~fragmentów teledysków wykorzystywanych w~opisywanym wcześniej zbiorze DEAP~\cite{deap_dataset_2011}.
	\item 36~fragmentów wyciętych z~hollywoodzkich filmów o~średnim czasie trwania 80~sekund.
\end{enumerate}
Podobnie jak w~przypadku pozostałych zbiorów, uczestnicy mieli ocenić każdy fragment przy pomocy następujących skal: \textit{valence} w~zakresie od -2~do 2, \textit{arousal} od 0~do 4~oraz \textit{dominance} o~zakresie takim jak w~przypadku \textit{arousal}. W~trakcie badań zebrano dane o~następujących sygnałach fizjologicznych: magnetoencefalogram (MEG), elektromiogram (EMG), elektrokardiogram (ECG). Pozyskano także nagrania twarzy każdego z~uczestników w~bliskiej podczerwieni. Sygnały były gromadzone z~próbkowaniem o~częstotliwości 1000~Hz, co daje dużą ilość danych, jednak może to wprowadzać wyraźne błędy w~pomiarach. Poza oryginalnymi odczytami, w~ramach zbioru zostały udostępnione wyliczone cechy dla każdego z~sygnałów, które mogą być wykorzystane jako gotowy zestaw danych wykorzystywanych do stworzenia modelu. Ze względu na generyczny sposób przetwarzania pomiarów we wszystkich używanych zbiorach, zdecydowano się skorzystać jednak z~oryginalnych wartości. 

\section{Przetworzenie danych}
%Opis preprocessingu, wykorzystane cechy
Ponieważ wykorzystane zbiory zostały udostępnione w~różnych formatach, a~odczyty w~nich zawarte różniły się długością pobranych danych, zakresami skal opisujących odczytywane emocje, a~w~przypadku zbioru DEAP innym rodzajem sygnału opisującego pracę serca, wymagane było przeprowadzenie wstępnej konwersji danych wejściowych. Każdy ze zbiorów udostępniał pomiary w~formacie plików MAT, które zostały otwarte przy pomocy biblioteki SciPy\footnote{\url{https://scipy.org/}}. Następnie, dla każdego ze zbiorów przeprowadzono proces przetworzenia danych przedstawiony na rysunku~\ref{fig:preprocessing_flow}. Ze względu na dostępność plików zawierającego ocenę jakości sygnałów oraz listę nieudanych eksperymentów, w~przypadku zbioru ASCERTAIN został przyjęty dodatkowy krok odrzucający przypadki zakończone niepowodzeniem, oraz te, dla których jakość sygnału z~elektrokardiogramu była oceniona na 6.
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.25\linewidth]{images/preprocessing_flow.png}
	\caption{Schemat przedstawiający proces przetworzenia danych do zbioru uczącego}
	\label{fig:preprocessing_flow}
\end{figure}

Mając identyfikator osoby i~eksperymentu, z~wczytanych danych zostały wyodrębnione sygnały z~elektrokardiogramu, a~w przypadku zbioru DEAP z~odczytów pulsu objętości krwi. Odczytano również wartości \textit{valence} i~\textit{arousal}, na podstawie których określony zostanie cel przygotowywanego modelu. Aby ujednolicić otrzymane oceny, przeskalowano je do zakresu od 1~do 9, a~następnie zamieniono na 9~klas, odpowiadających połączeniu 3~poziomów wartości dla każdej z~ocen, tak jak pokazano to na rysunku~\ref{fig:model_classes}. Taki podział pozwoli na objęcie stanów emocjonalnych charakteryzujących się niskim lub wysokim poziomem każdej z~ocen, uwzględniając jednocześnie wartości środkowe opisujące stan neutralny. Kolejnym krokiem było dostosowanie sygnałów do przetworzenia ich na cechy. Ponieważ reakcje fizjologiczne, które mogłyby wskazać na zmianę odczuwanej emocji, pojawiają się z~opóźnieniem w~stosunku do bodźca je wywołującego, wczytane dane zostały obcięte do ostatnich 50~sekund eksperymentu. Następnie, aby pozbyć się ewentualnych szumów i~wygładzić przebieg sygnałów, przefiltrowano je przy pomocy pasmowoprzepustowego filtru Butterwortha. Częstotliwości graniczne zostały dobrane na podstawie artykułu Fedotova~\cite{fedotov_optimal_cutoff_2016} poświęconego określeniu optymalnych wartości tych parametrów podczas filtrowania sygnału z~elektrokardiogramu.
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{images/model_classes.png}
	\caption{Podział ocen \textit{valence} i~\textit{arousal} na 9~klas}
	\label{fig:model_classes}
\end{figure}

Tak przygotowane dane zostały następnie wykorzystane do obliczenia cech, które zostaną użyte w~przygotowywanym modelu. Na początku z~sygnałów wyciągnięto interwały pomiędzy kolejnymi uderzeniami serca. Aby określić te wartości, w~przypadku sygnału z~elektrokardiogramu należało znaleźć położenia kolejnym załamków R, natomiast dla pomiarów pulsu objętości krwi kolejne powtórzenia danej fazy pracy serca. Do wykrycia tych punktów wykorzystana biblioteka PeakUtils\footnote{\url{https://scikit-learn.org/}} oferująca algorytm znajdujący wierzchołki w~podanym sygnale. Wymagany parametr minimalnej odległości pomiędzy kolejnych wierzchołkami był wyliczany na podstawie wzoru:
$$
\frac{60*f}{max_{hr}}
$$
gdzie $f$ oznaczało częstotliwość danych zbioru, z~którego pochodziła próbka sygnału, a~$max_{hr}$ przyjętą najwyższą możliwą wartość tętna. Eksperymentalnie została ona ustawiona na 135~uderzeń serca na minutę. Mając na uwadze fakt, że biblioteka mogła wykryć także nieprawidłowe położenia wierzchołków, po wyznaczeniu interwałów przefiltrowano je, odrzucając wartości znacznie odbiegające od mediany z~odczytów. Na podstawie odfiltrowanych danych obliczono ilości uderzeń serca na minutę, a~następnie określono następujące cechy statystyczne brane pod uwagę podczas uczenia modelu:
\begin{itemize}
	\item Minimalna i~maksymalna ilość uderzeń serca na minutę
	\item Średnia wartość tętna i~interwałów między uderzeniami
	\item Odchylenie standardowe tętna
	\item Kurtoza tętna i~interwałów --- opisuje, jak bardzo wyniki są skoncentrowane lub oddalone od średniej
	\item Współczynnik skośności dla tętna i~interwałów --- opisuje, jak dane rozkładają się wokół średniej.
	\item Procentowa ilość odczytów tętna i~interwałów powyżej wartości: $\text{średnia pomiaru} + \text{odchylenie standardowe}$
	\item Procentowa ilość odczytów  tętna i~interwałów poniżej wartości: $\text{średnia pomiaru} - \text{odchylenie standardowe}$
	\item Średnie odchylenie bezwględne (MAD) dla wartości interwałów pomiędzy uderzeniami serca.
\end{itemize}

Analizie została poddana także zmienność rytmu zatokowego, którą rozpatrzono jako parametry opisujące ją w~trzech dziedzinach. Pierwszą z~nich jest dziedzina czasu, w~ramach której można określić następujące parametry:
\begin{itemize}
	\item odchylenie standardowe interwałów pomiędzy kolejnymi uderzeniami (SDNN)
	\item średnia kwadratowa różnic pomiędzy kolejnymi interwałami (RMSSD)
	\item odchylenie standardowe różnic między kolejnymi interwałami (SDSD)
	\item procentowa ilość interwałów, które różnią się od poprzedniego interwału o~więcej niż 20~ms (pNN20)
	\item procentowa ilość interwałów, które różnią się od poprzedniego interwału o~więcej niż 50~ms (pNN50).
\end{itemize}
Kolejną z~dziedzin, w~ramach której rozpatrywana jest zmienność rytmu zatokowego, jest częstotliwość. 
Parametry w~ramach tej dziedziny zostały określone poprzez wygenerowanie periodogramu za pomocą metody Welcha~\cite{welch_1967} dostępnej jako funkcja w~bibliotece SciPy, a~następnie wyznaczeniu mocy widma w~zakresie określonych częstotliwości~\cite{hrv_overwiev_2017}:
\begin{itemize}
	\item 0.04--0.15 Hz --- zakres LF, dostarczający informacji o~krótkich zmianach w~tętnie
	\item 0.15--0.4 Hz --- zakres HF, dostarczający informacji o~zmianach związanych z~cyklem oddechowym.
\end{itemize}
Jako dodatkowy parametr wykorzystano także stosunek mocy sygnałów LF do HF. Wysoka wartość tej cechy jest widoczna w~sytuacjach polegających na walce lub ucieczce, natomiast wartości niskie w~przypadku zachowań pozytywnych, takich jak zawarcie przyjaźni.

Trzecią dziedziną, w~ramach której można przeprowadzić analizę zmienności rytmu zatokowego, jest dziedzina nieliniowa. Do analizy wyznaczany jest wykres Poincaré, przedstawiający korelację pomiędzy kolejnymi interwałami. Oznacza to, że współrzędne każdego z~punktów wykresu są opisane jako sąsiadujące wartości interwałów pomiędzy następującymi po sobie uderzeniami. Cechy wyznaczane w~ramach tej analizy to mała i~duża oś elipsy okalającej wszystkie punkty wykresu. Mała oś (SD1) jest to odchylenie standardowe odległości punktów od osi $y=x$ i~opisuje krótkoczasową zmienność rytmu serca. Duża oś natomiast odpowiada odchyleniu standardowemu odległości każdego z~punktów od osi $y=x+avg$, gdzie $avg$ oznacza średnią wartość interwałów. Odczyty z~tej osi opisują długoczasową zmienność rytmu serca. Jako dodatkową cechę wykorzystano także stosunek SD1 do SD2.

Dla każdego eksperymentu po wyznaczeniu wszystkich wyżej opisanych cech połączono je z~wcześniej wyznaczoną klasą i~dodano do zbioru uczącego. Przygotowany zbiór następnie przefiltrowano, usuwając przypadki, w~których brakowało przynajmniej jednej cechy. Ze względu na działania wykonywane podczas uczenia i~dopracowywania modelu, cechy nie zostały znormalizowane na etapie przetwarzania danych.

\section{Wybór modelu}
%Ewaluacja w~hyperopt, statystyki skuteczności, ostateczny wybór modelu
Do uczenia modelu na podstawie przygotowanego zbioru danych uczących zostały wykorzystane następujące klasyfikatory z~biblioteki scikit-learn\footnote{\url{https://scikit-learn.org/}}:
\begin{itemize}
	\item RandomForestClassifier
	\item ExtraTreesClassifier
	\item SupportVectorClassifier (SVC)
	\item KNeighborsClassifier
	\item GradientBoostingClassifier
\end{itemize}

W pierwszej iteracji wszystkie modele były uczone dla domyślnych wartości parametrów. Następnie, aby sprawdzić, czy skuteczności tak przygotowanych modeli są wiarygodne dla pomiarów spoza zbioru uczącego, przeprowadzono \textit{K}-krotną walidację krzyżową. Metoda ta polega na podzieleniu danych na \textit{K} podzbiorów, które następnie są wykorzystane do przeprowadzenia \textit{K} iteracji uczenia modelu, gdzie jako dane uczące wybieranych jest \textit{K}-1 podzbiorów, natomiast ostatni jest wykorzystywany jako wartości testowe. W~wyniku przeprowadzenia walidacji zostaje wygenerowanych \textit{K} modeli o~określonych skutecznościach, które następnie można wykorzystać do obliczenia średniej skuteczności modelu. W~obu przypadkach cechy ostały poddane standaryzacji. Wartości procentowe skuteczności zarówno dla przypadku domyślnego, jak i~walidacji krzyżowej przedstawia tabela~\ref{tab:models_accuracies}.

\begin{table}
	\centering
	\caption{Skuteczności wybranych modeli przy określonych parametrach}
	\label{tab:models_accuracies}
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{Algorytm} & \textbf{\begin{tabular}[c]{@{}l@{}}Skuteczność\\ dla domyślnych\\ parametrów\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Skuteczność\\ po przeprowadzeniu\\ walidacji krzyżowej\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Skuteczność\\ po  optymalizacji\\ parametrów\end{tabular}} \\ \hline
		RandomForestClassifier      & 28\%                 & 27\%                                                                                                  & 35\%                                                                                        \\ \hline
		ExtraTreesClassifier        & 31\%                 & 29\%                                                                                                  & 36\%                                                                                        \\ \hline
		SVC               & 25\%                 & 25\%                                                                                                  & 28\%                                                                                        \\ \hline
		GradientBoostingClassifier               & 24\%                 & 24\%                                                                                                  & -                                                                                         \\ \hline
		KNeighboursClassifier               & 21\%                 & 24\%                                                                                                  & -                                                                                       \\ \hline
	\end{tabular}
\end{table}

Aby osiągnąć większą dokładność, należało przeprowadzić optymalizację parametrów. Zdecydowano się ją wykonać jedynie dla modeli o~skuteczności wyższej lub równej 25\%. Wykorzystana została do tego biblioteka hyperopt-sklearn\footnote{\url{http://hyperopt.github.io/hyperopt-sklearn/}} pozwalająca na odszukanie jak najlepszych parametrów modelu w~zależności od zadanych danych wejściowych. Funkcja estymująca na wejściu przyjmuje klasyfikator, dla którego chcemy znaleźć parametry, sposób normalizacji cech, liczbę konfiguracji, dla których ma zostać przeprowadzona analiza oraz maksymalny czas, w~jakim każda z~prób powinna się zakończyć. Dla każdego z~modeli liczba prób została ustalona na 100, natomiast maksymalny czas dla prób ustawiony został na 5~minut. Parametr odpowiadający za normalizację cech ustawiono na wartość dowolną, dzięki czemu estymator będzie mógł także znaleźć funkcję normalizującą cechy wraz z~jej właściwościami, która w~połączeniu ze znalezionymi parametrami klasyfikatora da najlepsze wyniki. Skuteczności modeli po optymalizacji ich parametrów oraz funkcji do normalizacji cech przedstawione zostały w~ostatniej kolumnie tabeli~\ref{tab:models_accuracies}. Największy przyrost, a~jednocześnie najwyższą wartość skuteczności wynoszącą 36\% można zauważyć dla klasyfikatora wykorzystujące drzewa ekstremalnie losowe. Dla tego modelu została ponownie przeprowadzona optymalizacja parametrów, tym razem dla dłuższego czasu maksymalnego i~liczby prób równej 1200, jednak wynik poprawił się zaledwie o~1\%. 

Taka skuteczność nie pozwala na pewne rozpoznawanie emocji na podstawie odczytów samej pracy serca. Głównym powodem może być tutaj fakt, że wykorzystane fragmenty sygnałów były na tyle długie, że w~trakcie badania użytkownicy mogli odczuwać więcej niż jedną emocję. Ponieważ nie jest jeszcze obecnie możliwe powiązanie wzorców zmian w~reakcjach fizjologicznych z~konkretnymi emocjami przy pomocy wzorów, nie było także możliwości wyboru odpowiednich fragmentów sygnałów w~zależności od eksperymentu. Możliwe, że dołączenie do analizy pomiarów na temat reakcji elektrodermalnej lub odczytów z~elektroencefalogramu pozwoliłoby na uzyskanie wyższej skuteczności, jednak wykorzystanie sensorów mierzących te sygnały mogłoby wprowadzić wysoki dyskomfort podczas użytkowania, co kolidowałoby z~wymaganiami architektury sprzętowej przygotowywanego interfejsu. Skuteczność rozpoznawania emocji przy pomocy wybranego modelu może zostać poprawiona dzięki odczytom z~akcelerometru wbudowanego w~kontroler. Ostateczny sposób wyliczania i~interpretacja stanów emocjonalnych na podstawie przygotowanego modelu oraz pomiarów z~akcelerometru zostanie opisana w~rozdziale~\ref{cha:implementacja}.